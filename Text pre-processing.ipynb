{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['Body']=news['Body'].apply(lambda x: re.sub('—','',x))#removing dashses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['Body']=news['Body'].apply(lambda x: x.strip())#removing leading or trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of English Contractions\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the reviews\n",
    "news['Headline']=news['Headline'].apply(lambda x:expand_contractions(x))\n",
    "news['Body']=news['Body'].apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all of the alphabets to lower because python treats 'T' and 't' as different .\n",
    "news['Headline']=news['Headline'].apply(lambda x: x.lower())\n",
    "news['Body']=news['Body'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all the punctuations\n",
    "news['Headline']=news['Headline'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "news['Body']=news['Body'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       daniel greenfield a shillman journalism fellow...\n",
       "1       google pinterest digg linkedin reddit stumbleu...\n",
       "2       us secretary of state john f kerry said monday...\n",
       "3       kaydee king kaydeeking november 9 2016 the les...\n",
       "4       it is primary day in new york and frontrunners...\n",
       "                              ...                        \n",
       "6330    the state department told the republican natio...\n",
       "6331    the ‘p’ in pbs should stand for ‘plutocratic’ ...\n",
       "6332    antitrump protesters are tools of the oligarch...\n",
       "6333    addis ababa ethiopia president obama convened ...\n",
       "6334    jeb bush is suddenly attacking trump here is w...\n",
       "Name: Body, Length: 6335, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unwanted symbols and numbers\n",
    "news['Body']=news['Body'].apply(lambda x: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \",x))\n",
    "news['Headline']=news['Headline'].apply(lambda x: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \",x))\n",
    "#removing numbers\n",
    "news1['Body']=news1['Body'].apply(lambda x: re.sub('\\w*\\d\\w*','', str(x)))\n",
    "news1['Headline']=news1['Headline'].apply(lambda x: re.sub('\\w*\\d\\w*','', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "news['Headline']=news['Headline'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "news['Body']=news['Body'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned data saved to news_updated.csv\n",
    "news1=pd.read_csv('news_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>smell hillary fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>us secretary state john f kerry said monday st...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bernie supporters twitter erupt anger dnc trie...</td>\n",
       "      <td>kaydee king kaydeeking november 9 2016 lesson ...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>battle new york primary matters</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0                                 smell hillary fear   \n",
       "1  watch exact moment paul ryan committed politic...   \n",
       "2                    kerry go paris gesture sympathy   \n",
       "3  bernie supporters twitter erupt anger dnc trie...   \n",
       "4                    battle new york primary matters   \n",
       "\n",
       "                                                Body label  length  \n",
       "0  daniel greenfield shillman journalism fellow f...  FAKE    7518  \n",
       "1  google pinterest digg linkedin reddit stumbleu...  FAKE    2646  \n",
       "2  us secretary state john f kerry said monday st...  REAL    2543  \n",
       "3  kaydee king kaydeeking november 9 2016 lesson ...  FAKE    2660  \n",
       "4  primary day new york frontrunners hillary clin...  REAL    1840  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing numbers\n",
    "news1['Body']=news1['Body'].apply(lambda x: re.sub('\\w*\\d\\w*','', str(x)))\n",
    "news1['Headline']=news1['Headline'].apply(lambda x: re.sub('\\w*\\d\\w*','', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>smell hillary fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>us secretary state john f kerry said monday st...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bernie supporters twitter erupt anger dnc trie...</td>\n",
       "      <td>kaydee king kaydeeking november   lesson tonig...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>battle new york primary matters</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0                                 smell hillary fear   \n",
       "1  watch exact moment paul ryan committed politic...   \n",
       "2                    kerry go paris gesture sympathy   \n",
       "3  bernie supporters twitter erupt anger dnc trie...   \n",
       "4                    battle new york primary matters   \n",
       "\n",
       "                                                Body label  length  \n",
       "0  daniel greenfield shillman journalism fellow f...  FAKE    7518  \n",
       "1  google pinterest digg linkedin reddit stumbleu...  FAKE    2646  \n",
       "2  us secretary state john f kerry said monday st...  REAL    2543  \n",
       "3  kaydee king kaydeeking november   lesson tonig...  FAKE    2660  \n",
       "4  primary day new york frontrunners hillary clin...  REAL    1840  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "w_tokenizer=nltk.tokenize.WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(sent):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(sent)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "news1['lemma_headline']=news1['Headline'].apply(lambda x: lemma(str(x)))\n",
    "news1['lemma_body']=news1['Body'].apply(lambda x: lemma(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>lemma_headline</th>\n",
       "      <th>lemma_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>smell hillary fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7518</td>\n",
       "      <td>smell hillary fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2646</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>us secretary state john f kerry said monday st...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2543</td>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>u secretary state john f kerry said monday sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bernie supporters twitter erupt anger dnc trie...</td>\n",
       "      <td>kaydee king kaydeeking november   lesson tonig...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2660</td>\n",
       "      <td>bernie supporter twitter erupt anger dnc tried...</td>\n",
       "      <td>kaydee king kaydeeking november lesson tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>battle new york primary matters</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1840</td>\n",
       "      <td>battle new york primary matter</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0                                 smell hillary fear   \n",
       "1  watch exact moment paul ryan committed politic...   \n",
       "2                    kerry go paris gesture sympathy   \n",
       "3  bernie supporters twitter erupt anger dnc trie...   \n",
       "4                    battle new york primary matters   \n",
       "\n",
       "                                                Body label  length  \\\n",
       "0  daniel greenfield shillman journalism fellow f...  FAKE    7518   \n",
       "1  google pinterest digg linkedin reddit stumbleu...  FAKE    2646   \n",
       "2  us secretary state john f kerry said monday st...  REAL    2543   \n",
       "3  kaydee king kaydeeking november   lesson tonig...  FAKE    2660   \n",
       "4  primary day new york frontrunners hillary clin...  REAL    1840   \n",
       "\n",
       "                                      lemma_headline  \\\n",
       "0                                 smell hillary fear   \n",
       "1  watch exact moment paul ryan committed politic...   \n",
       "2                    kerry go paris gesture sympathy   \n",
       "3  bernie supporter twitter erupt anger dnc tried...   \n",
       "4                     battle new york primary matter   \n",
       "\n",
       "                                          lemma_body  \n",
       "0  daniel greenfield shillman journalism fellow f...  \n",
       "1  google pinterest digg linkedin reddit stumbleu...  \n",
       "2  u secretary state john f kerry said monday sto...  \n",
       "3  kaydee king kaydeeking november lesson tonight...  \n",
       "4  primary day new york frontrunners hillary clin...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "news1['Body+Headline']=news1[['lemma_headline' , 'lemma_body']].apply(lambda x: ' '.join(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>lemma_headline</th>\n",
       "      <th>lemma_body</th>\n",
       "      <th>Body+Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>smell hillary fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>7518</td>\n",
       "      <td>smell hillary fear</td>\n",
       "      <td>daniel greenfield shillman journalism fellow f...</td>\n",
       "      <td>smell hillary fear daniel greenfield shillman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2646</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "      <td>watch exact moment paul ryan committed politic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>us secretary state john f kerry said monday st...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>2543</td>\n",
       "      <td>kerry go paris gesture sympathy</td>\n",
       "      <td>u secretary state john f kerry said monday sto...</td>\n",
       "      <td>kerry go paris gesture sympathy u secretary st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bernie supporters twitter erupt anger dnc trie...</td>\n",
       "      <td>kaydee king kaydeeking november   lesson tonig...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>2660</td>\n",
       "      <td>bernie supporter twitter erupt anger dnc tried...</td>\n",
       "      <td>kaydee king kaydeeking november lesson tonight...</td>\n",
       "      <td>bernie supporter twitter erupt anger dnc tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>battle new york primary matters</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>1840</td>\n",
       "      <td>battle new york primary matter</td>\n",
       "      <td>primary day new york frontrunners hillary clin...</td>\n",
       "      <td>battle new york primary matter primary day new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0                                 smell hillary fear   \n",
       "1  watch exact moment paul ryan committed politic...   \n",
       "2                    kerry go paris gesture sympathy   \n",
       "3  bernie supporters twitter erupt anger dnc trie...   \n",
       "4                    battle new york primary matters   \n",
       "\n",
       "                                                Body label  length  \\\n",
       "0  daniel greenfield shillman journalism fellow f...  FAKE    7518   \n",
       "1  google pinterest digg linkedin reddit stumbleu...  FAKE    2646   \n",
       "2  us secretary state john f kerry said monday st...  REAL    2543   \n",
       "3  kaydee king kaydeeking november   lesson tonig...  FAKE    2660   \n",
       "4  primary day new york frontrunners hillary clin...  REAL    1840   \n",
       "\n",
       "                                      lemma_headline  \\\n",
       "0                                 smell hillary fear   \n",
       "1  watch exact moment paul ryan committed politic...   \n",
       "2                    kerry go paris gesture sympathy   \n",
       "3  bernie supporter twitter erupt anger dnc tried...   \n",
       "4                     battle new york primary matter   \n",
       "\n",
       "                                          lemma_body  \\\n",
       "0  daniel greenfield shillman journalism fellow f...   \n",
       "1  google pinterest digg linkedin reddit stumbleu...   \n",
       "2  u secretary state john f kerry said monday sto...   \n",
       "3  kaydee king kaydeeking november lesson tonight...   \n",
       "4  primary day new york frontrunners hillary clin...   \n",
       "\n",
       "                                       Body+Headline  \n",
       "0  smell hillary fear daniel greenfield shillman ...  \n",
       "1  watch exact moment paul ryan committed politic...  \n",
       "2  kerry go paris gesture sympathy u secretary st...  \n",
       "3  bernie supporter twitter erupt anger dnc tried...  \n",
       "4  battle new york primary matter primary day new...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
